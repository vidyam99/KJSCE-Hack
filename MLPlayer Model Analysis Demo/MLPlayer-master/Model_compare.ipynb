{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_compare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidyam99/MLPlayer/blob/master/Model_compare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMg4nK9s9Y7W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "19145409-8ba6-4f0f-f073-fe331f96f5c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXsANGyI9WlX",
        "colab_type": "code",
        "outputId": "27cc3e58-f41a-42d0-94c9-2264525957df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "source": [
        "# Compare Algorithms\n",
        "import pandas\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV,train_test_split\n",
        "import time\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "# load dataset\n",
        "#url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "#url=\"https://drive.google.com/open?id=1TF3yLanhUwmKDe9mpiKh5wGFLww3kkic\"\n",
        "#url=\"https://drive.google.com/open?id=1231TVD-_CsnBoMLKZ4O9y2qZsyifLJpx\"\n",
        "#names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "#dataframe = pandas.read_csv(url, names=names)\n",
        "#print(dataframe)\n",
        "url=\"drive/My Drive/diabetes.csv\"\n",
        "dataframe = pandas.read_csv(url,error_bad_lines=False)\n",
        "col=len(dataframe.columns)-1\n",
        "#print(dataframe)\n",
        "#print(dataframe.shape)\n",
        "data=dataframe.iloc[:,0:col]\n",
        "#print(data)\n",
        "labels=dataframe.iloc[:,col-1]\n",
        "class_col=col\n",
        "array = dataframe.values\n",
        "X = array[:,0:col]\n",
        "Y = array[:,class_col]\n",
        "#print(X)\n",
        "#print(Y)\n",
        "\n",
        "# prepare configuration for cross validation test harness\n",
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('SVM', SVC()))\n",
        "models.append(('RFC',RandomForestClassifier()))\n",
        "models.append(('GB',GradientBoostingClassifier()))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "Models=['LogisticRegression','KNeighborsClassifier','DecisionTreeClassifier','SVC','RFC','GB','LinearDiscriminantAnalysis','GaussianNB']\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "best=0\n",
        "sec_best=0\n",
        "scoring = 'accuracy'\n",
        "i=0\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
        "\tcv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tif cv_results.mean()>best:\n",
        "\t\tbest=cv_results.mean()\n",
        "\t\tmo=i\n",
        "\telif best>cv_results.mean()>sec_best:\n",
        "\t\tsec_best=cv_results.mean()\n",
        "\t\tmb=i\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "\ti+=1\n",
        "print(f\"Predicted model={Models[mo]}\")\n",
        "print(f\"Second best model={Models[mb]}\")\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()\n",
        "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
        "\tdata, labels, test_size=0.25, random_state=42)\n",
        "ch=mo\n",
        "if ch==7 or ch==8:\n",
        "\tch=0\n",
        "if ch==0:\n",
        "\tprint(\"No hyperparameters\")\n",
        "else:\n",
        "\tif ch==1:\n",
        "\t\t#For LogisticRegression--------------------------------------------------------------->\n",
        "\t\tfrom sklearn.linear_model import LogisticRegression\n",
        "\t\tmodel = LogisticRegression(penalty='l2')\n",
        "\t\tdual=[True,False] \n",
        "\t\tmax_iter=[100,110,120,130,140]\n",
        "\t\tC = [1.0,1.5,2.0,2.5]\n",
        "\t\tparams = dict(dual=dual,max_iter=max_iter,C=C)\n",
        "\telif ch==2:\n",
        "\t\t#For DecisionTreeClassifier----------------------------------------------------------->\n",
        "\t\tfrom sklearn.tree import DecisionTreeClassifier\n",
        "\t\t#making the instance\n",
        "\t\tmodel= DecisionTreeClassifier(random_state=1234)\n",
        "\t\t#Hyper Parameters Set\n",
        "\t\tparams = {'max_features': ['auto', 'sqrt', 'log2'],\n",
        "\t\t'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
        "\t\t'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],\n",
        "\t\t'random_state':[123]}\n",
        "\telif ch==3:\n",
        "\t\t#For SVC------------------------------------------------------------------------------->\n",
        "\t\tfrom sklearn.svm import SVC\n",
        "\t\tmodel=SVC(max_iter=1500)\n",
        "\t\t#Hyper Parameters Set\n",
        "\t\tparams = {'C': [6,7,8,9,10,11,12], \n",
        "\t\t'kernel': ['linear','rbf']}\n",
        "\telif ch==4:\n",
        "\t\t#For RandomForestClassifier----------------------------------------------------------->\n",
        "\t\t#making the instance\n",
        "\t\tmodel=RandomForestClassifier()\n",
        "\t\t#hyper parameters set\n",
        "\t\tparams = {'criterion':['gini','entropy'],\n",
        "\t\t'n_estimators':[10,15,20,25,30],\n",
        "\t\t'min_samples_leaf':[1,2,3],\n",
        "\t\t'min_samples_split':[3,4,5,6,7], \n",
        "\t\t'random_state':[123],\n",
        "\t\t'n_jobs':[-1]}\n",
        "\telif ch==5:\n",
        "\t\t#FOr GradientBoostingClassifier------------------------------------------------------->\n",
        "\t\tfrom sklearn.ensemble import GradientBoostingClassifier\n",
        "\t\tmodel=GradientBoostingClassifier()\n",
        "\t\tparams = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
        "\telif ch==6:\n",
        "\t\t#For KNN------------------------------------------------------------------------------->\n",
        "\t\tfrom sklearn.neighbors import KNeighborsClassifier\n",
        "\t\t#making the instance\n",
        "\t\tmodel = KNeighborsClassifier(n_jobs=-1)\n",
        "\t\t#Hyper Parameters Set\n",
        "\t\tparams = {'n_neighbors':[5,6,7,8,9,10],\n",
        "\t\t'leaf_size':[1,2,3,5],\n",
        "\t\t'weights':['uniform', 'distance'],\n",
        "\t\t'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
        "\t\t'n_jobs':[-1]}\n",
        "\"\"\"#ForLDA-------------------------------------------------------------------------------->\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "#For GaussianNB------------------------------------------------------------------------>\n",
        "from sklearn.naive_bayes import GaussianNB\"\"\"\n",
        "import time\n",
        "random = RandomizedSearchCV(estimator=model, param_distributions=params, cv = 3, n_jobs=-1)\n",
        "\n",
        "start_time = time.time()\n",
        "random_result = random.fit(X, Y)\n",
        "random.predict(testData)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\n",
        "kfold = KFold(n_splits=3, random_state=7)\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "print(result.mean())\n",
        "\"\"\"estimator=SVC()\n",
        "print(estimator.get_params())\n",
        "params = {\"n_neighbors\": np.arange(1, 31, 2),\n",
        "\t\"metric\": [\"euclidean\", \"cityblock\"]}\n",
        "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
        "\tdata, labels, test_size=0.25, random_state=42)\n",
        "model = KNeighborsClassifier(n_jobs=1)\n",
        "models=GaussianNB()\n",
        "grid = RandomizedSearchCV(model, params)\n",
        "start = time.time()\n",
        "grid.fit(trainData, trainLabels)\"\"\"\n",
        " \n",
        "# evaluate the best randomized searched model on the testing\n",
        "# data\n",
        "\"\"\"print(\"[INFO] randomized search took {:.2f} seconds\".format(\n",
        "\ttime.time() - start))\n",
        "acc = grid.score(testData, testLabels)\n",
        "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
        "print(\"[INFO] randomized search best parameters: {}\".format(\n",
        "\tgrid.best_params_))\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LR: 0.769515 (0.048411)\n",
            "KNN: 0.726555 (0.061821)\n",
            "CART: 0.699163 (0.055555)\n",
            "SVM: 0.651025 (0.072141)\n",
            "RFC: 0.753845 (0.075823)\n",
            "GB: 0.764286 (0.059284)\n",
            "LDA: 0.773462 (0.051592)\n",
            "NB: 0.755178 (0.042766)\n",
            "Predicted model=LinearDiscriminantAnalysis\n",
            "Second best model=GB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEVCAYAAAAM3jVmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlpD/D5zwA5hz5HAOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.736979 using {'weights': 'uniform', 'n_neighbors': 10, 'n_jobs': -1, 'leaf_size': 5, 'algorithm': 'brute'}\n",
            "Execution time: 1.954843521118164 ms\n",
            "0.71484375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'print(\"[INFO] randomized search took {:.2f} seconds\".format(\\n\\ttime.time() - start))\\nacc = grid.score(testData, testLabels)\\nprint(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\\nprint(\"[INFO] randomized search best parameters: {}\".format(\\n\\tgrid.best_params_))'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvy1OI4f9WNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d477c935-76a1-44af-eda7-0b69978854be"
      },
      "source": [
        "lr = LogisticRegression(penalty='l1',dual=False,max_iter=110)\n",
        "lr.fit(X,Y)\n",
        "lr.score(X,Y)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7799479166666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmGuoOjcCE89",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de8a71bd-cfe6-4f81-d19a-4d580e72533e"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "kfold = KFold(n_splits=3, random_state=7)\n",
        "result = cross_val_score(lr, X, Y, cv=kfold, scoring='accuracy')\n",
        "print(result.mean())``"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.76953125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yco0ZjI5CjN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"from sklearn.model_selection import GridSearchCV\n",
        "dual=[True,False]\n",
        "max_iter=[100,110,120,130,140]\n",
        "C = [1.0,1.5,2.0,2.5]\n",
        "param_grid = dict(dual=dual,max_iter=max_iter,C=C)\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy4TvR70MZOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "55370c58-8cae-41a3-f036-93aef314ae0a"
      },
      "source": [
        "ch=1\n",
        "if ch==1:\n",
        "  #For LogisticRegression--------------------------------------------------------------->\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  model = LogisticRegression(penalty='l2')\n",
        "  dual=[True,False] \n",
        "  max_iter=[100,110,120,130,140]\n",
        "  C = [1.0,1.5,2.0,2.5]\n",
        "  params = dict(dual=dual,max_iter=max_iter,C=C)\n",
        "elif ch==2:\n",
        "  #For DecisionTreeClassifier----------------------------------------------------------->\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  #making the instance\n",
        "  model= DecisionTreeClassifier(random_state=1234)\n",
        "  #Hyper Parameters Set\n",
        "  params = {'max_features': ['auto', 'sqrt', 'log2'],\n",
        "          'min_samples_split': [2,3,4,5,6,7,8,9,10,11,12,13,14,15], \n",
        "          'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10,11],\n",
        "          'random_state':[123]}\n",
        "elif ch==3:\n",
        "  #For SVC------------------------------------------------------------------------------->\n",
        "  from sklearn.svm import SVC\n",
        "  model=SVC(max_iter=1500)\n",
        "  #Hyper Parameters Set\n",
        "  params = {'C': [6,7,8,9,10,11,12], \n",
        "          'kernel': ['linear','rbf']}\n",
        "elif ch==4:\n",
        "  #For RandomForestClassifier----------------------------------------------------------->\n",
        "  #making the instance\n",
        "  model=RandomForestClassifier()\n",
        "  #hyper parameters set\n",
        "  params = {'criterion':['gini','entropy'],\n",
        "          'n_estimators':[10,15,20,25,30],\n",
        "          'min_samples_leaf':[1,2,3],\n",
        "          'min_samples_split':[3,4,5,6,7], \n",
        "          'random_state':[123],\n",
        "          'n_jobs':[-1]}\n",
        "elif ch==5:\n",
        "  #FOr GradientBoostingClassifier------------------------------------------------------->\n",
        "  from sklearn.ensemble import GradientBoostingClassifier\n",
        "  model=GradientBoostingClassifier(n_estimators = 10, random_state = 42)\n",
        "  params = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
        "  #base_model = GradientBoostingClassifier(n_estimators = 10, random_state = 42)\n",
        "  base_model.fit(trainData, trainLabels)\n",
        "  base_accuracy = evaluate(base_model, testData, testLabels)\n",
        "elif ch==6:\n",
        "  #For KNN------------------------------------------------------------------------------->\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  #making the instance\n",
        "  model = KNeighborsClassifier(n_jobs=-1)\n",
        "  #Hyper Parameters Set\n",
        "  params = {'n_neighbors':[5,6,7,8,9,10],\n",
        "          'leaf_size':[1,2,3,5],\n",
        "          'weights':['uniform', 'distance'],\n",
        "          'algorithm':['auto', 'ball_tree','kd_tree','brute'],\n",
        "          'n_jobs':[-1]}\n",
        "\"\"\"#ForLDA-------------------------------------------------------------------------------->\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "#For GaussianNB------------------------------------------------------------------------>\n",
        "from sklearn.naive_bayes import GaussianNB\"\"\"\n",
        "import time\n",
        "random = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, cv = 3, n_jobs=-1)\n",
        "\n",
        "start_time = time.time()\n",
        "random_result = random.fit(X, Y)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\n",
        "kfold = KFold(n_splits=3, random_state=7)\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "print(result.mean())"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.772135 using {'max_iter': 140, 'dual': False, 'C': 2.0}\n",
            "Execution time: 0.2710578441619873 ms\n",
            "0.765625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ql1GDICqd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "88a87444-ef66-4519-e78b-72b94c49d3f9"
      },
      "source": [
        "import time\n",
        "\n",
        "#lr = LogisticRegression(penalty='l2')\n",
        "#grid = GridSearchCV(estimator=model, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
        "grid = GridSearchCV(model, param_grid=params, n_jobs=1)\n",
        "start_time = time.time()\n",
        "grid_result = grid.fit(X, Y)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "kfold = KFold(n_splits=3, random_state=7)\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "print(result.mean())\n",
        "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.764323 using {'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 2, 'random_state': 123}\n",
            "0.6796875\n",
            "Execution time: 2.1578192710876465 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUUSs2lDDT0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a8MPo6lDZSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "feb49853-e8dd-4180-f215-02393360875e"
      },
      "source": [
        "random = RandomizedSearchCV(estimator=lr, param_distributions=param_grid, cv = 3, n_jobs=-1)\n",
        "\n",
        "start_time = time.time()\n",
        "random_result = random.fit(X, Y)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
        "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')\n",
        "kfold = KFold(n_splits=3, random_state=7)\n",
        "result = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "print(result.mean())"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best: 0.773438 using {'max_iter': 120, 'dual': False, 'C': 2.5}\n",
            "Execution time: 0.24812865257263184 ms\n",
            "0.71484375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e-oqWxp5K8z",
        "colab_type": "code",
        "outputId": "dbcb025e-4668-4d75-e5bc-051a5725f94b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "def evaluate(model, test_features, test_labels):                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
        "    predictions = model.predict(test_features)\n",
        "    errors = abs(predictions - test_labels)\n",
        "    mape = 100 * np.mean(errors / test_labels)\n",
        "    accuracy = 100 - mape\n",
        "    print('Model Performance')\n",
        "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
        "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
        "    return accuracy\n",
        "#GradientBoostingClassifier\n",
        "base_model = GradientBoostingClassifier(n_estimators = 10, random_state = 42)\n",
        "base_model.fit(trainData, trainLabels)\n",
        "base_accuracy = evaluate(base_model, testData, testLabels)\n",
        "#RandomForestCLassifier\n",
        "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
        "base_model.fit(trainData, trainLabels)\n",
        "base_accuracy = evaluate(base_model, testData, testLabels)\n",
        "#RandomForestRegressor\n",
        "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
        "base_model.fit(trainData, trainLabels)\n",
        "base_accuracy = evaluate(base_model, testData, testLabels)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-fc3b196c974b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#GradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbase_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mbase_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#RandomForestCLassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainData' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWJ93nzz67yn",
        "colab_type": "code",
        "outputId": "bc237da0-5b58-40a6-b3f6-aa040d4c762c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Number of trees in random forest\n",
        "import numpy as np\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(random_grid)\n",
        "rf = RandomForestRegressor()\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(train_features, train_labels)\n",
        "rf_random.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqUKkjxxyyLZ",
        "colab_type": "code",
        "outputId": "5bf0f5a6-f916-4341-b5a4-94f32e82614f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV,train_test_split\n",
        "import time\n",
        "#from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, train_test_split\n",
        "# construct the set of hyperparameters to tune\n",
        "params = {\"n_neighbors\": np.arange(1, 31, 2),\n",
        "\t\"metric\": [\"euclidean\", \"cityblock\"]}\n",
        "(trainData, testData, trainLabels, testLabels) = train_test_split(\n",
        "\tdata, labels, test_size=0.25, random_state=42)\n",
        "model = KNeighborsClassifier(n_jobs=2)\n",
        "grid = RandomizedSearchCV(model, params)\n",
        "start = time.time()\n",
        "grid.fit(trainData, trainLabels)\n",
        " \n",
        "# evaluate the best randomized searched model on the testing\n",
        "# data\n",
        "print(\"[INFO] randomized search took {:.2f} seconds\".format(\n",
        "\ttime.time() - start))\n",
        "acc = grid.score(testData, testLabels)\n",
        "print(\"[INFO] grid search accuracy: {:.2f}%\".format(acc * 100))\n",
        "print(\"[INFO] randomized search best parameters: {}\".format(\n",
        "\tgrid.best_params_))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
            "  % (min_groups, self.n_splits)), Warning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] randomized search took 0.32 seconds\n",
            "[INFO] grid search accuracy: 13.54%\n",
            "[INFO] randomized search best parameters: {'n_neighbors': 21, 'metric': 'cityblock'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}